{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c47a7d8",
   "metadata": {},
   "source": [
    "first we import all whats needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76984732",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2                                  # for video processing and drawing\n",
    "import numpy as np                          # for all numerical operations\n",
    "from collections import OrderedDict         # Keeps track of objects in the order they were added\n",
    "from scipy.spatial import distance as dist  # Computes pairwise distances between points (used for tracking)\n",
    "from IPython.display import Video, HTML, display\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa85ac2",
   "metadata": {},
   "source": [
    "Here the needed funktions shall be added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4950e013",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def nms_boxes(boxes, scores, iou_thresh=0.30):\n",
    "    \"\"\"Simple Non-Maximum Suppression for [x1,y1,x2,y2] boxes.\"\"\"\n",
    "    boxes = np.array(boxes, dtype=float)\n",
    "    scores = np.array(scores, dtype=float)\n",
    "    if len(boxes) == 0:\n",
    "        return []\n",
    "\n",
    "    x1, y1, x2, y2 = boxes[:,0], boxes[:,1], boxes[:,2], boxes[:,3]\n",
    "    areas = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
    "    order = scores.argsort()[::-1]  # high score first\n",
    "    keep = []\n",
    "\n",
    "    while order.size > 0:\n",
    "        i = order[0]\n",
    "        keep.append(i)\n",
    "        xx1 = np.maximum(x1[i], x1[order[1:]])\n",
    "        yy1 = np.maximum(y1[i], y1[order[1:]])\n",
    "        xx2 = np.minimum(x2[i], x2[order[1:]])\n",
    "        yy2 = np.minimum(y2[i], y2[order[1:]])\n",
    "        w = np.maximum(0.0, xx2 - xx1 + 1)\n",
    "        h = np.maximum(0.0, yy2 - yy1 + 1)\n",
    "        inter = w * h\n",
    "        iou = inter / (areas[i] + areas[order[1:]] - inter)\n",
    "        # nur Boxen behalten, die wenig Überschneidung haben\n",
    "        inds = np.where(iou <= iou_thresh)[0]\n",
    "        order = order[inds + 1]\n",
    "    return keep\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7547d66b",
   "metadata": {},
   "source": [
    "now all needed pathes were added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c8fb578",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path       = \"../videos/CarsOnAHighway_30fps.mp4\"        # the video we do use\n",
    "prototxt_path    = \"../models/deploy.prototxt\"                 # the network architecture of MobileNetSSD \n",
    "model_path       = \"../models/mobilenet_iter_73000.caffemodel\" # the trained weights of MobileNetSSD \n",
    "output_path      = \"../output_tracked.mp4\"                     # the video we do want to create\n",
    "output_path_h264 = \"../output_tracked_h264.mp4\"             # the video we do want to create with h264 codec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f858c3",
   "metadata": {},
   "source": [
    "check if the file was executed already, if so delete all craeted files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c83b4ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted: ../output_tracked.mp4\n",
      "Deleted: ../output_tracked_h264.mp4\n"
     ]
    }
   ],
   "source": [
    "\n",
    "files_to_delete = [output_path, output_path_h264]\n",
    "\n",
    "for file in files_to_delete:\n",
    "    if os.path.exists(file):\n",
    "        try:\n",
    "            os.remove(file)\n",
    "            print(f\"Deleted: {file}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error deleting {file}: {e}\")\n",
    "    else:\n",
    "        print(f\"Not found: {file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68097506",
   "metadata": {},
   "source": [
    "Load MobileNetSSD - what happens here is that the architecture information and the calculated weights are taken and a model is created out of that.\n",
    "A list is created with all detectable opbjects to have an ID <-> name relation later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a9cc4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = cv2.dnn.readNetFromCaffe(prototxt_path, model_path)\n",
    "CLASSES = [\"background\", \"aeroplane\", \"bicycle\", \"bird\", \"boat\",\n",
    "           \"bottle\", \"bus\", \"car\", \"cat\", \"chair\", \"cow\", \"diningtable\",\n",
    "           \"dog\", \"horse\", \"motorbike\", \"person\", \"pottedplant\", \"sheep\",\n",
    "           \"sofa\", \"train\", \"tvmonitor\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084bf350",
   "metadata": {},
   "source": [
    "now the improved centraid tracker is created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f2a2d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Improved Centroid Tracker\n",
    "class CentroidTracker:\n",
    "    def __init__(self, maxDisappeared=50):      # C O N S T R U C T O R:\n",
    "        self.nextObjectID = 0                   # here the next upcoming object ID is storeded (used in register())\n",
    "        self.objects = OrderedDict()            # a dictionary is created for all existing objects - ID:[X-pos, Y-Pos]\n",
    "        self.disappeared = OrderedDict()        # a dictionary is created - info how long a object was invisible ID:frames\n",
    "        self.maxDisappeared = maxDisappeared\n",
    "        \n",
    "    # register a newly found car \n",
    "    # centroid - the x / y possition of the objet as an Humpy Array\n",
    "    def register(self, centroid):                   \n",
    "        self.objects[self.nextObjectID] = centroid  # create a dictonary entry for the object and store its position\n",
    "        self.disappeared[self.nextObjectID] = 0     # create a dictonary entry for the objects dissapearance timer and set it to Zero\n",
    "        self.nextObjectID += 1                      # calculate the next object ID\n",
    "\n",
    "    # if the car is gone, kick it out\n",
    "    def deregister(self, objectID):\n",
    "        del self.objects[objectID]\n",
    "        del self.disappeared[objectID]\n",
    "\n",
    "    # update each object separatly by stepping through all objects detected in n-dimensional array rects\n",
    "    def update(self, rects):\n",
    "        if len(rects) == 0:                                           # if no object was found you can delete them all\n",
    "            for objectID in list(self.disappeared.keys()):            # for all remaining objects\n",
    "                self.disappeared[objectID] += 1                       # increment the dissapearance counter\n",
    "                if self.disappeared[objectID] > self.maxDisappeared:  # if gobe for to long\n",
    "                    self.deregister(objectID)                         # delete this object\n",
    "            return self.objects                                       # jump back\n",
    "\n",
    "        inputCentroids = np.zeros((len(rects), 2), dtype=\"int\")       # create a empty numpy array element for each found objects and its coordinates (reservaze space only)\n",
    "        for (i, (startX, startY, endX, endY)) in enumerate(rects):    # step through all and map all rects elements to i, startX, startY, endX, endY\n",
    "            cX = int((startX + endX) / 2.0)                           # calculate the center X position\n",
    "            cY = int((startY + endY) / 2.0)                           # calculate the center Y position\n",
    "            inputCentroids[i] = (cX, cY)                              # store the center positions in the numpy array inputCentroids[i]\n",
    "\n",
    "        if len(self.objects) == 0:                                    # check how many objects are \"alive\" right now\n",
    "            for i in range(len(inputCentroids)):                      # looks like none, so create them all\n",
    "                self.register(inputCentroids[i])                      \n",
    "        else:                                                         # looks like there is a living object\n",
    "            objectIDs = list(self.objects.keys())                     # get all current object dicts ID:[x,y]\n",
    "            objectCentroids = list(self.objects.values())             # get all current object IDs\n",
    "\n",
    "            D = dist.cdist(np.array(objectCentroids), inputCentroids) # compute the distance between each pair of stored/new centroids\n",
    "            rows = D.min(axis=1).argsort()                            # find the smallest distance fro each ID inthe newdata\n",
    "            cols = D.argmin(axis=1)[rows]                             # find the index of the smallest distance for each stored object and store it in cols\n",
    "\n",
    "            usedRows = set()\n",
    "            usedCols = set()\n",
    "\n",
    "            for (row, col) in zip(rows, cols):                        # step through all found rows and columns\n",
    "                if row in usedRows or col in usedCols:                # if either the row or column is already used, skip it\n",
    "                    continue\n",
    "                objectID = objectIDs[row]                             # get the object ID for the current row\n",
    "                self.objects[objectID] = inputCentroids[col]          # update the ID:[x,y] of the object with the new centroid\n",
    "                self.disappeared[objectID] = 0                        # remeber that you've seen this object\n",
    "                usedRows.add(row)                                     # mark the row as used \n",
    "                usedCols.add(col)                                     # mark the column as used\n",
    "\n",
    "            unusedRows = set(range(0, D.shape[0])).difference(usedRows) # find all unused rows - to mark them as unvisible\n",
    "            unusedCols = set(range(0, D.shape[1])).difference(usedCols) # find all unused columns - to mark them as new objects\n",
    "\n",
    "            \n",
    "            for row in unusedRows:                                    # step through all not existing anymore objects\n",
    "                objectID = objectIDs[row]                             # get the object ID for the current row\n",
    "                self.disappeared[objectID] += 1                       # increment the dissapearance counter\n",
    "                if self.disappeared[objectID] > self.maxDisappeared:  # if gone for to long\n",
    "                    self.deregister(objectID)                         # delete this object\n",
    "\n",
    "            for col in unusedCols:                                    # step through all new objects\n",
    "                self.register(inputCentroids[col])                    # register each new object\n",
    "\n",
    "\n",
    "        return self.objects\n",
    "\n",
    "# fianlly create the tracker object\n",
    "tracker = CentroidTracker()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0fc8898",
   "metadata": {},
   "source": [
    "Open the video and store it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95cf22aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opened: True\n"
     ]
    }
   ],
   "source": [
    "# Open video\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "print(\"Opened:\", cap.isOpened())\n",
    "\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77eb67b",
   "metadata": {},
   "source": [
    "create a VideoWriter for output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a812020",
   "metadata": {},
   "outputs": [],
   "source": [
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce7a937",
   "metadata": {},
   "source": [
    "Now do the magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c112c933",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_count = 0\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    frame_count += 1\n",
    "    \n",
    "    (h, w) = frame.shape[:2]\n",
    "    blob = cv2.dnn.blobFromImage(cv2.resize(frame, (300, 300)), 0.007843, (300, 300), 127.5)\n",
    "    net.setInput(blob)\n",
    "    detections = net.forward()\n",
    "\n",
    "#    rects = []\n",
    "#    for i in range(detections.shape[2]):\n",
    "#        confidence = detections[0, 0, i, 2]\n",
    "#        if confidence > 0.4:\n",
    "#            idx = int(detections[0, 0, i, 1])\n",
    "#            if CLASSES[idx] in [\"car\", \"bus\", \"person\"]:\n",
    "#                box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "#                rects.append(box.astype(\"int\"))\n",
    "\n",
    "    CONF_THRESH = 0.55          # etwas höher für stabilere Boxen\n",
    "    NMS_THRESH  = 0.30          # übliches NMS-IoU\n",
    "\n",
    "    rects, scores, classes = [], [], []\n",
    "\n",
    "    for i in range(detections.shape[2]):\n",
    "        conf = float(detections[0, 0, i, 2])\n",
    "        if conf >= CONF_THRESH:\n",
    "            idx = int(detections[0, 0, i, 1])\n",
    "            label = CLASSES[idx]\n",
    "            if label in [\"car\", \"bus\", \"person\"]:\n",
    "                box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])  # [x1,y1,x2,y2]\n",
    "                rects.append(box.astype(int))\n",
    "                scores.append(conf)\n",
    "                classes.append(label)\n",
    "\n",
    "    # NMS anwenden (nur wenn es überhaupt Boxen gibt)\n",
    "    if rects:\n",
    "        keep_idx = nms_boxes(rects, scores, iou_thresh=NMS_THRESH)\n",
    "        rects   = [rects[i]   for i in keep_idx]\n",
    "        classes = [classes[i] for i in keep_idx]\n",
    "    else:\n",
    "        rects, classes = [], []\n",
    "        \n",
    "    objects = tracker.update(rects)\n",
    "\n",
    "    for (objectID, centroid) in objects.items():\n",
    "        text = f\"ID {objectID}\"\n",
    "        cv2.putText(frame, text, (centroid[0] - 10, centroid[1] - 10),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "        cv2.circle(frame, (centroid[0], centroid[1]), 4, (0, 255, 0), -1)\n",
    "\n",
    "    out.write(frame)\n",
    "\n",
    "# Release resources AFTER loop\n",
    "cap.release()\n",
    "out.release()\n",
    "\n",
    "print(f\"Frames processed: {frame_count}\")\n",
    "print(\"Annotated video with persistent IDs saved as output_tracked.mp4\")\n",
    "print(\"To display in Jupyter, use:\")\n",
    "print(\"from IPython.display import Video; Video('output_tracked.mp4', embed=True)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd62fb8",
   "metadata": {},
   "source": [
    "No make it available in Jupiter Labs - need to convert it...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e53ef37",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# JupyterLab video display helpers (Codespaces-safe)\n",
    "# --------------------------------------------------\n",
    "# Drop this in a new cell AFTER writing your video file.\n",
    "# It embeds the MP4 inline (IPython Video widget) and also via raw HTML as fallback.\n",
    "# If inline playback fails (codec issue), see the optional ffmpeg conversion block below.\n",
    "\n",
    "\n",
    "\n",
    "VIDEO_IN = output_path\n",
    "VIDEO_OUT = VIDEO_IN.replace('.mp4', '_h264.mp4')\n",
    "WIDTH = 800\n",
    "\n",
    "if not os.path.exists(VIDEO_IN):\n",
    "    raise FileNotFoundError(f\"Input video not found: {VIDEO_IN}\")\n",
    "\n",
    "# 1) Ensure ffmpeg is available via imageio\n",
    "try:\n",
    "    import imageio_ffmpeg\n",
    "except ImportError:\n",
    "    !pip -q install imageio[ffmpeg]\n",
    "    import imageio_ffmpeg\n",
    "\n",
    "ffmpeg_path = imageio_ffmpeg.get_ffmpeg_exe()\n",
    "print('Using ffmpeg at:', ffmpeg_path)\n",
    "\n",
    "# 2) Run conversion to H.264 + yuv420p + faststart\n",
    "import subprocess\n",
    "cmd = [\n",
    "    ffmpeg_path, '-y', '-i', VIDEO_IN,\n",
    "    '-c:v', 'libx264', '-preset', 'veryfast', '-crf', '23',\n",
    "    '-pix_fmt', 'yuv420p', '-movflags', '+faststart',\n",
    "    '-c:a', 'aac', '-b:a', '128k',\n",
    "    VIDEO_OUT\n",
    "]\n",
    "print('Converting ->', VIDEO_OUT)\n",
    "proc = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "if proc.returncode != 0:\n",
    "    print(proc.stdout)\n",
    "    print(proc.stderr)\n",
    "    raise RuntimeError('ffmpeg conversion failed')\n",
    "\n",
    "print('OK:', VIDEO_OUT)\n",
    "\n",
    "# 3) Embed converted video\n",
    "try:\n",
    "    display(Video(VIDEO_OUT, embed=True, width=WIDTH))\n",
    "except Exception as e:\n",
    "    print('Embed failed:', e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
